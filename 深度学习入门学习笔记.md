# 深度学习入门笔记

## 第一章 Python入门
1. Python3.x写的代码不能被Python2.x所执行。
2. Python属于动态类型语言，变量类型根据情况自动决定。
3. Python的逻辑运算符`and or not`
4. Python构造类的格式：
```Python
class className:
    def __init__(self,parameters):
        xxx
    def function1(self,parameters):
        xxx
    def function2(self,parameters):
        xxx
```
`__init__`方法是进行初始化，也称构造函数(constructor)只在生成类的实例时被调用一次。  

5. *一个奇技淫巧*`X[X>15]`取出方括号内值为`True`的元素。
6. 
```Python
plt.plot(x,y,linestyle='',label='')#参数分别表示横轴，纵轴，线形和标签
plt.xlabel('') #横轴标签
plt.ylabel('') #纵轴标签
plt.title('') #标题
plt.legend() #显示图例
plt.show() #显示图像
```
7. matplotlib读取和显示图像
```Python
import matplotlib.pyplot as plt
from matplotlib.image import imread
img = imread('path.png')
plt.imshow(img)
plt.show()
```
## 第二章 感知机
1. 感知机(perceptron)接收多个信号，输出一个信号。
输入信号被送往感知机（神经元）时会分别乘以固定的权重(w<sub>1</sub>x<sub>1</sub>、w<sub>2</sub>x<sub>2</sub>)神经元会计算信号的总和，超过阈值时输出1，称为神经元被激活，阈值用符号&theta;表示。
公式表示为：$$y=\left\{\begin{array}{ll}
0 & \left(w_{1} x_{1}+w_{2} x_{2} \leqslant \theta\right) \\
1 & \left(w_{1} x_{1}+w_{2} x_{2}>\theta\right)
\end{array}\right. $$
2. 感知机的行为：$$ y=\left\{\begin{array}{ll}
0 & \left(b+w_{1} x_{1}+w_{2} x_{2} \leqslant 0\right) \\
1 & \left(b+w_{1} x_{1}+w_{2} x_{2}>0\right)
\end{array}\right. $$ b称为偏置，调整神经元被激活的容易程度，w<sub>1</sub>和w<sub>2</sub>称为权重，控制输入信号的重要性参数。
## 第三章 神经网络
1. 用图表示神经网络，最左边的称为**输入层**，最右边一列称为**输出层**，中间的称为**中间层**，有时也称为**隐藏层**。
2. 将输入信号的总和转换为输出信号称为**激活函数**(activation function)。
   * sigmoid函数(sigmoid function)：$$ h(x)=\frac{1}{1+\exp (-x)}$$
   * 阶跃函数图像![20210118210607](https://raw.githubusercontent.com/RayYoh/PicGo/master/20210118210607.png)
   sigmoid函数与阶跃函数：
   ![20210118220335](https://raw.githubusercontent.com/RayYoh/PicGo/master/20210118220335.png)
   * ReLU函数![20210118221355](https://raw.githubusercontent.com/RayYoh/PicGo/master/20210118221355.png)
3. 输出层的激活函数，回归问题用**恒等函数**，二元分类函数使用**sigmoid函数**，多元分类函数使用**softmax函数**。
   softmax函数：$$y_{k}=\frac{\exp \left(a_{k}\right)}{\sum_{i=1}^{n} \exp \left(a_{i}\right)}$$ 这一的函数在计算机中在数值很大的情况下可能出现溢出的情况，因此对其改造：
   ![20210119105328](https://raw.githubusercontent.com/RayYoh/PicGo/master/20210119105328.png) softmax的输出为0.0-1.0之间的实数，可称之为概率。
4. 把数据限定到某个范围内的处理称为**正规化(normalization)**.对神经网络进行某种既定的转换称为**预处理(pre-processing)**。
5. 打包式的输入数据称为**批(batch)**.可大幅缩短处理时间。